{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Dimensional NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1478 3877 3676 2333 2539]\n",
      "[   0 5355 5701 4952 6410 5509  324    2 5223 5385]\n",
      "[[ 2  3  4]\n",
      " [ 6  7  8]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "import numpy as np\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print (ridership[1, 3])\n",
    "    print (ridership[1:3, 3:5])\n",
    "    print (ridership[1, :])\n",
    "    \n",
    "# Vectorized operations on rows or columns\n",
    "if True:\n",
    "    print (ridership[0, :] + ridership[1, :])\n",
    "    print (ridership[:, 0] + ridership[:, 1])\n",
    "    \n",
    "# Vectorized operations on entire arrays\n",
    "if True:\n",
    "    a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    print (a + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    overall_mean = None # Replace this with your code\n",
    "    mean_for_max = None # Replace this with your code\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "print mean_riders_for_max_station(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy axis argument\n",
    "if False:\n",
    "    a = np.array([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ])\n",
    "    \n",
    "    print a.sum()\n",
    "    print a.sum(axis=0)\n",
    "    print a.sum(axis=1)\n",
    "    \n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "    '''\n",
    "    max_daily_ridership = None     # Replace this with your code\n",
    "    min_daily_ridership = None     # Replace this with your code\n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Elements of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# DataFrame creation\n",
    "if False:\n",
    "    # You can create a DataFrame out of a dictionary mapping column names to values\n",
    "    df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df_1\n",
    "\n",
    "    # You can also use a list of lists or a 2D NumPy array\n",
    "    df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "    print df_2\n",
    "   \n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print ridership_df.iloc[0]\n",
    "    print ridership_df.loc['05-05-11']\n",
    "    print ridership_df['R003']\n",
    "    print ridership_df.iloc[1, 3]\n",
    "    \n",
    "# Accessing multiple rows\n",
    "if False:\n",
    "    print ridership_df.iloc[1:4]\n",
    "    \n",
    "# Accessing multiple columns\n",
    "if False:\n",
    "    print ridership_df[['R003', 'R005']]\n",
    "    \n",
    "# Pandas axis\n",
    "if False:\n",
    "    df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df.sum()\n",
    "    print df.sum(axis=1)\n",
    "    print df.values.sum()\n",
    "    \n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "    '''\n",
    "    overall_mean = None # Replace this with your code\n",
    "    mean_for_max = None # Replace this with your code\n",
    "    \n",
    "    return (overall_mean, mean_for_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "filename = path+'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "entries = subway_df['ENTRIESn_hourly']\n",
    "cum_entries = subway_df['ENTRIESn']\n",
    "rain = subway_df['meanprecipi']\n",
    "temp = subway_df['meantempi']\n",
    "\n",
    "print correlation(entries, rain)\n",
    "print correlation(entries, temp)\n",
    "print correlation(rain, temp)\n",
    "\n",
    "print correlation(entries, cum_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of vectorized operations on DataFrames:\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "    \n",
    "# Adding DataFrames with overlapping column names \n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "\n",
    "# Adding DataFrames with overlapping row indexes\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print df1 + df2\n",
    "\n",
    "# --- Quiz ---\n",
    "# Cumulative entries and exits for one station for a few hours.\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe applymap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame applymap()\n",
    "if False:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "    \n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print df.applymap(add_one)\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "    \n",
    "def convert_grades(grades):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "    \n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply()\n",
    "if False:\n",
    "    def convert_grades_curve(exam_grades):\n",
    "        # Pandas has a bult-in function that will perform this calculation\n",
    "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "        # the qcut() function here:\n",
    "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "        return pd.qcut(exam_grades,\n",
    "                       [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                       labels=['F', 'D', 'C', 'B', 'A'])\n",
    "        \n",
    "    # qcut() operates on a list, array, or Series. This is the\n",
    "    # result of running the function on a single column of the\n",
    "    # DataFrame.\n",
    "    print convert_grades_curve(grades_df['exam1'])\n",
    "    \n",
    "    # qcut() does not work on DataFrames, but we can use apply()\n",
    "    # to call the function on each column separately\n",
    "    print grades_df.apply(convert_grades_curve)\n",
    "    \n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame apply() Use Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply() - use case 2\n",
    "if False:   \n",
    "    print df.apply(np.mean)\n",
    "    print df.apply(np.max)\n",
    "    \n",
    "def second_largest(df):\n",
    "    '''\n",
    "    Fill in this function to return the second-largest value of each \n",
    "    column of the input DataFrame.\n",
    "    '''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a DataFrame to a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding a Series to a one-row DataFrame \n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "\n",
    "# Adding a Series to a one-column DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "\n",
    "    \n",
    "# Adding when DataFrame column names match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding when DataFrame column names don't match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Each Column Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding using +\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding with axis='index'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='index')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "# Adding with axis='columns'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='columns')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    \n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Examine DataFrame\n",
    "if False:\n",
    "    print example_df\n",
    "    \n",
    "# Examine groups\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Group by multiple columns\n",
    "if False:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Get sum of each group\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data.sum()\n",
    "    \n",
    "# Limit columns in result\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print grouped_data.sum()['value']\n",
    "    \n",
    "    print '\\n' # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print grouped_data['value'].sum()\n",
    "    \n",
    "path = './' #Assuming the file is in current directory. Change it to whatever directory the file is in\n",
    "filename = path + 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Hourly Entries and Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Standardize each group\n",
    "if False:\n",
    "    def standardize(xs):\n",
    "        return (xs - xs.mean()) / xs.std()\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(standardize)\n",
    "    \n",
    "# Find second largest value in each group\n",
    "if False:\n",
    "    def second_largest(xs):\n",
    "        sorted_xs = xs.sort(inplace=False, ascending=False)\n",
    "        return sorted_xs.iloc[1]\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(second_largest)\n",
    "\n",
    "# --- Quiz ---\n",
    "# DataFrame with cumulative entries and exits for multiple stations\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits and return a DataFrame with hourly entries and exits.\n",
    "    The hourly entries and exits should be calculated separately for\n",
    "    each station (the 'UNIT' column).\n",
    "    \n",
    "    Hint: Take a look at the `get_hourly_entries_and_exits()` function\n",
    "    you wrote in a previous quiz, DataFrame Vectorized Operations. If\n",
    "    you copy it here and rename it, you can use it and the `.apply()`\n",
    "    function to help solve this problem.\n",
    "    '''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# groupby() without as_index\n",
    "if False:\n",
    "    first_even = example_df.groupby('even').first()\n",
    "    print first_even\n",
    "    print first_even['even'] # Causes an error. 'even' is no longer a column in the DataFrame\n",
    "    \n",
    "# groupby() with as_index=False\n",
    "if False:\n",
    "    first_even = example_df.groupby('even', as_index=False).first()\n",
    "    print first_even\n",
    "    print first_even['even'] # Now 'even' is still a column in the DataFrame\n",
    "    \n",
    "path = './' #Assuming the file is in current directory. Change it to whatever directory the file is in\n",
    "filename = path + 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "## Make a plot of your choice here showing something interesting about the subway data.\n",
    "## Matplotlib documentation here: http://matplotlib.org/api/pyplot_api.html\n",
    "## Once you've got something you're happy with, share it on the forums!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
