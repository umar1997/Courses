{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.542\n",
      "6\n",
      "[0 0 0 1 0 1 1 1 0 1]\n",
      "98 tornadoes back to back in 2739.72602739726\n"
     ]
    }
   ],
   "source": [
    "# Distribution\n",
    "# Binary Distribution e.g Flipping a coin 100 times\n",
    "import numpy as np\n",
    "print(np.random.binomial(1,0.5)) # First param is the number of times we want it to run\n",
    "# Second is the chance we get a 0\n",
    "print(np.random.binomial(1000,0.5)/1000)\n",
    "#######################################\n",
    "# Doesnt neccesarily have to been evenly weighted\n",
    "chance_of_tornado  = 0.01/100\n",
    "print(np.random.binomial(100000,chance_of_tornado))\n",
    "######################################\n",
    "# Whats the chance of having this 2 days in a row\n",
    "chance_of_tornado  = 0.5\n",
    "print(np.random.binomial(1,chance_of_tornado,10))\n",
    "#####################################\n",
    "chance_of_tornado  = 0.01\n",
    "tornadoEvents = np.random.binomial(1,chance_of_tornado,1000000)\n",
    "twoDaysInaRow = 0\n",
    "for j in range(1,len(tornadoEvents)-1):\n",
    "    if tornadoEvents[j] == 1 and tornadoEvents[j-1] ==1:\n",
    "        twoDaysInaRow +=1\n",
    "print(str(twoDaysInaRow) + ' tornadoes back to back in ' + str(1000000/365))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0261251053072324\n",
      "*******************\n",
      "0.17215460049152265\n",
      "*******************\n",
      "-0.06863197483991408\n",
      "*******************\n",
      "2.1065780560990452\n",
      "1.4193212865930556\n"
     ]
    }
   ],
   "source": [
    "# More Distributions\n",
    "# X label is the Value of the distribution Y label is the Probability Observation occurs\n",
    "\n",
    "# If the values are the same and is a flat line (Uniform Distribution)\n",
    "# If bell shaped curve then the distribution is (Guassian Distribution)\n",
    "\n",
    "# Standard Deviation\n",
    "distr = np.random.normal(0.75, size = 1000) # 1000 samples from a normall distribution with expected value of 0.75\n",
    "distr\n",
    "print(np.sqrt(np.sum((np.mean(distr)-distr)**2)/len(distr)))\n",
    "np.std(distr)\n",
    "print('*******************')\n",
    "\n",
    "# Shape of the tails of the distribution (kurtosis)\n",
    "# -ve value means curve is alittle more flat than a normal\n",
    "# +ve means the curve is a bit more peaky than a normal\n",
    "import scipy.stats as stats\n",
    "print(stats.kurtosis(distr))\n",
    "print('*******************')\n",
    "print(stats.skew(distr))\n",
    "\n",
    "# The Chi Squared Distribution has only one parameter called the degrees of freedom. \n",
    "# The degrees of freedom is closely related to the number of samples that you take from \n",
    "# a normal population. It's important for significance testing. But what I would like you \n",
    "# to observe, is that as the degrees of freedom increases, the shape of the Chi Squared distribution \n",
    "# changes. In particular, the skew to the left begins to move towards the center. \n",
    "print('*******************')\n",
    "chidf = np.random.chisquare(2, size = 10000) # 2 is the dof\n",
    "print(stats.skew(chidf)) # We can see the skew is quite large\n",
    "# If we inc the dof we can see the skew dec\n",
    "chidf = np.random.chisquare(5, size = 10000)\n",
    "print(stats.skew(chidf))\n",
    "\n",
    "# Bimodal Distribution (2 peaks)\n",
    "# We can model these using two normal distributions with different parameters\n",
    "# These are called Guassian Mixture Models, which are useful when clustering data\n",
    "\n",
    "\n",
    "\n",
    "# Note: A distribution is just a shape that describes the probability of a value being \n",
    "# pulled when we sample a population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************\n",
      "*******************\n",
      "assignment1_grade    74.972741\n",
      "assignment2_grade    67.252190\n",
      "assignment3_grade    61.129050\n",
      "assignment4_grade    54.157620\n",
      "assignment5_grade    48.634643\n",
      "assignment6_grade    43.838980\n",
      "dtype: float64\n",
      "*******************\n",
      "Ttest_indResult(statistic=1.400549944897566, pvalue=0.16148283016060577)\n",
      "*******************\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis Testing\n",
    "# A hypothesis is a statement that we can test\n",
    "# Alternate Hypothesis: Our Idea\n",
    "# Null Hypothesis: The alternate of our idea\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./CSV Files/grades.csv')\n",
    "# print(df.head())\n",
    "print('*******************')\n",
    "early = df[df['assignment1_submission']<='2015-12-31']\n",
    "# print(early.head())\n",
    "late = df[df['assignment1_submission']>'2015-12-31']\n",
    "# print(late.head())\n",
    "print('*******************')\n",
    "# The mean of all the grades\n",
    "print(early.mean())\n",
    "print('*******************')\n",
    "# When doing hypothesis testing, we have to choose a significance level as a threshold \n",
    "# for how much of a chance we're willing to accept. This significance level is typically \n",
    "# called alpha (Critical value) Typically 0.1, 0.01, 0.05\n",
    "\n",
    "#A T test is one way to compare the means of two different populations\n",
    "# Will compare two independent samples to see if they have different means\n",
    "print(stats.ttest_ind(early['assignment1_grade'], late['assignment1_grade']))\n",
    "# The result is a statistics and a pvalue\n",
    "# pvalue is much greater than 0.05 thus we cant reject the null hypothesis\n",
    "# If we keep on doing this on diff assignments till we get a positive result it is p-hacking or dredging\n",
    "print('*******************')\n",
    "# When a data scientist run many tests in this way, it's called p-hacking or dredging \n",
    "# and it's a serious methodological issue. P-hacking results in spurious correlations \n",
    "# instead of generalizable results.\n",
    "# Remedies: \n",
    "# 1) Bonferroni Correction: If alpha = 0.05, and running 3 datas divide 0.05 by 3 and that is new alpha\n",
    "# 2) Hold Out Sets: Test on half of each data, make new hypothesis, then test on rest of data\n",
    "# aka Cross Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
